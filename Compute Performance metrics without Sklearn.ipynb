{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>predicted_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637387</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635165</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766586</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889199</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba  predicted_val\n",
       "0  1.0  0.637387            1.0\n",
       "1  1.0  0.635165            1.0\n",
       "2  1.0  0.766586            1.0\n",
       "3  1.0  0.724564            1.0\n",
       "4  1.0  0.889199            1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "import pandas as pd\n",
    "data= pd.read_csv(\"5_a.csv\")\n",
    "data['predicted_val'] =(data.proba>=0.5).astype('float')\n",
    "data.head()\n",
    "#k = data.proba.tolist()\n",
    "#print(k)\n",
    "#print(k.sort(reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "def tp(y,predicted_val):\n",
    "    return sum((y == 1)&(predicted_val == 1))\n",
    "def fn(y,predicted_val):\n",
    "    return sum((y == 1)&(predicted_val == 0))\n",
    "def fp(y,predicted_val):\n",
    "    return sum((y == 0)&(predicted_val == 1))\n",
    "def tn(y,predicted_val):\n",
    "    return sum((y == 0)&(predicted_val == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 10000\n",
      "FN: 0\n",
      "FP: 100\n",
      "TN: 0\n"
     ]
    }
   ],
   "source": [
    "print('TP:',tp(data.y.values,data.predicted_val.values))\n",
    "print('FN:',fn(data.y.values,data.predicted_val.values))\n",
    "print('FP:',fp(data.y.values,data.predicted_val.values))\n",
    "print('TN:',tn(data.y.values,data.predicted_val.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,   100],\n",
       "       [    0, 10000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confusion_matrix(y,predicted_val):\n",
    "    TP = tp(y,predicted_val)\n",
    "    FN = fn(y,predicted_val)\n",
    "    FP = fp(y,predicted_val)\n",
    "    TN= tn(y,predicted_val)\n",
    "    return TP,FN,FP,TN\n",
    "def The_confusion_matrix(y,predicted_val):\n",
    "    TP,FN,FP,TN =  confusion_matrix(y,predicted_val)\n",
    "    return np.array([[TN,FP],[FN,TP]])\n",
    "The_confusion_matrix(data.y.values,data.predicted_val.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,   100],\n",
       "       [    0, 10000]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing values by using sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(data.y.values,data.predicted_val.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1 score and accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9900990099009901\n",
      "recall: 1.0\n",
      "F1score 0.9950248756218906\n",
      "accuracy 0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "TP = tp(data.y.values,data.predicted_val.values)\n",
    "FN = fn(data.y.values,data.predicted_val.values)\n",
    "FP = fp(data.y.values,data.predicted_val.values)\n",
    "TN = tn(data.y.values,data.predicted_val.values)\n",
    "acr = ((TP+TN)/(TP+TN+FP+FN))\n",
    "pr =(TP/(TP+FP))\n",
    "#pr =(10000/(10000+100))\n",
    "re = TP/(FN+TP)\n",
    "print(\"precision:\",+pr)\n",
    "print(\"recall:\",+re)\n",
    "f1 = ((2*pr*re)/(pr+re))\n",
    "print(\"F1score\",+f1)\n",
    "print(\"accuracy\",+acr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9900990099009901\n",
      "F1 score 0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "#comparing values with sklearn\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "print(\"accuracy score\",accuracy_score(data.y.values,data.predicted_val.values))\n",
    "print(\"F1 score\",f1_score(data.y.values,data.predicted_val.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>predicted_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba  predicted_val\n",
       "0  0.0  0.281035            0.0\n",
       "1  0.0  0.465152            0.0\n",
       "2  0.0  0.352793            0.0\n",
       "3  0.0  0.157818            0.0\n",
       "4  0.0  0.276648            0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "import pandas as pd\n",
    "data= pd.read_csv(\"5_b.csv\")\n",
    "data['predicted_val'] =(data.proba>=0.5).astype('float')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10100/10100 [02:54<00:00, 57.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The auc score without using sklearn: 0.48829900000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data=pd.read_csv('5_a.csv')\n",
    "negative_points= data['y'].value_counts()[0] \n",
    "positive_points = data['y'].value_counts()[1]\n",
    "tpr_array = [] \n",
    "fpr_array = [] \n",
    "sorted_data = data.sort_values('proba',ascending = False)\n",
    "for threshold in tqdm(sorted_data['proba']):\n",
    "    y_pred = [] \n",
    "    for k in sorted_data['proba']:\n",
    "        \n",
    "        if (k<threshold):\n",
    "            y_pred.append(0.0)\n",
    "        else:\n",
    "            y_pred.append(1.0)\n",
    "    sorted_data['y_pred'] = y_pred\n",
    "    for k in data:\n",
    "        TP = ((sorted_data['y']==1.0) & (sorted_data['y_pred'] == 1.0)).sum()   \n",
    "        FP = ((sorted_data['y']==0.0) & (sorted_data['y_pred'] == 1.0)).sum()\n",
    "    tpr_array.append( TP/positive_points)\n",
    "    fpr_array.append(FP/negative_points)\n",
    "auc = np.trapz(tpr_array,fpr_array)\n",
    "print(\"The auc score without using sklearn:\",auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Compute performance metrics for the given data 5_b.csv\n",
    "   Note 1: in this data you can see number of positive points << number of negatives points\n",
    "   Note 2: use pandas or numpy to read the data from 5_b.csv\n",
    "   Note 3: you need to derive the class labels from given score\n",
    "ypred=[0 if y_score < 0.5 else 1]ypred=[0 if y_score < 0.5 else 1] \n",
    "\n",
    " 1.Compute Confusion Matrix \n",
    "\n",
    " 2.Compute F1 Score \n",
    "\n",
    " 3.Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) https://stackoverflow.com/q/53603376/4084039, https://stackoverflow.com/a/39678975/4084039\n",
    "\n",
    " 4.Compute Accuracy Score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>predicted_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba  predicted_val\n",
       "0  0.0  0.281035            0.0\n",
       "1  0.0  0.465152            0.0\n",
       "2  0.0  0.352793            0.0\n",
       "3  0.0  0.157818            0.0\n",
       "4  0.0  0.276648            0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "import pandas as pd\n",
    "data= pd.read_csv(\"5_b.csv\")\n",
    "data['predicted_val'] =(data.proba>=0.5).astype('float')\n",
    "data.head()\n",
    "#k = data.proba.tolist()\n",
    "#print(k)\n",
    "#print(k.sort(reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "def tp(y,predicted_val):\n",
    "    return sum((y == 1)&(predicted_val == 1))\n",
    "def fn(y,predicted_val):\n",
    "    return sum((y == 1)&(predicted_val == 0))\n",
    "def fp(y,predicted_val):\n",
    "    return sum((y == 0)&(predicted_val == 1))\n",
    "def tn(y,predicted_val):\n",
    "    return sum((y == 0)&(predicted_val == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 55\n",
      "FN: 45\n",
      "FP: 239\n",
      "TN: 9761\n"
     ]
    }
   ],
   "source": [
    "print('TP:',tp(data.y.values,data.predicted_val.values))\n",
    "print('FN:',fn(data.y.values,data.predicted_val.values))\n",
    "print('FP:',fp(data.y.values,data.predicted_val.values))\n",
    "print('TN:',tn(data.y.values,data.predicted_val.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9761,  239],\n",
       "       [  45,   55]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confusion_matrix(y,predicted_val):\n",
    "    TP = tp(y,predicted_val)\n",
    "    FN = fn(y,predicted_val)\n",
    "    FP = fp(y,predicted_val)\n",
    "    TN= tn(y,predicted_val)\n",
    "    return TP,FN,FP,TN\n",
    "def The_confusion_matrix(y,predicted_val):\n",
    "    TP,FN,FP,TN =  confusion_matrix(y,predicted_val)\n",
    "    return np.array([[TN,FP],[FN,TP]])\n",
    "The_confusion_matrix(data.y.values,data.predicted_val.values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9761,  239],\n",
       "       [  45,   55]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing values by using sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(data.y.values,data.predicted_val.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1 score and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.1870748299319728\n",
      "recall: 0.55\n",
      "F1score: 0.2791878172588833\n",
      "accuracy: 0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "FN = fn(data.y.values,data.predicted_val.values)\n",
    "FP = fp(data.y.values,data.predicted_val.values)\n",
    "TN = tn(data.y.values,data.predicted_val.values)\n",
    "TP = tp(data.y.values,data.predicted_val.values)\n",
    "acr = ((TP+TN)/(TP+TN+FP+FN))\n",
    "pr =(TP/(TP+FP))\n",
    "#pr =(10000/(10000+100))\n",
    "re = TP/(FN+TP)\n",
    "print(\"precision:\",+pr)\n",
    "print(\"recall:\",+re)\n",
    "f1 = ((2*pr*re)/(pr+re))\n",
    "print(\"F1score:\",+f1)\n",
    "print(\"accuracy:\",+acr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.9718811881188119\n",
      "F1 score 0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "#comparing values with sklearn\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "print(\"accuracy score\",accuracy_score(data.y.values,data.predicted_val.values))\n",
    "print(\"F1 score\",f1_score(data.y.values,data.predicted_val.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10100/10100 [02:40<00:00, 63.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The auc score without using sklearn: 0.9377570000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data=pd.read_csv('5_b.csv')\n",
    "negative_points= data['y'].value_counts()[0] \n",
    "positive_points = data['y'].value_counts()[1]\n",
    "tpr_array = [] \n",
    "fpr_array = [] \n",
    "sorted_data = data.sort_values('proba',ascending = False)\n",
    "for threshold in tqdm(sorted_data['proba']):\n",
    "    y_pred = [] \n",
    "    for k in sorted_data['proba']:\n",
    "        \n",
    "        if (k<threshold):\n",
    "            y_pred.append(0.0)\n",
    "        else:\n",
    "            y_pred.append(1.0)\n",
    "    sorted_data['y_pred'] = y_pred\n",
    "    for k in data:\n",
    "        TP = ((sorted_data['y']==1.0) & (sorted_data['y_pred'] == 1.0)).sum()   \n",
    "        FP = ((sorted_data['y']==0.0) & (sorted_data['y_pred'] == 1.0)).sum()\n",
    "    tpr_array.append( TP/positive_points)\n",
    "    fpr_array.append(FP/negative_points)\n",
    "auc = np.trapz(tpr_array,fpr_array)\n",
    "print(\"The auc score without using sklearn:\",auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.412057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.375579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y      prob\n",
       "0  0  0.458521\n",
       "1  0  0.505037\n",
       "2  0  0.418652\n",
       "3  0  0.412057\n",
       "4  0  0.375579"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "import pandas as pd\n",
    "data= pd.read_csv(\"5_c.csv\")\n",
    "#len(data)\n",
    "data.head()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matric value:  141000\n",
      "Threshold value:  0.2300390278970873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_prob = list(sorted(set(data['prob'])))\n",
    "A=100000000\n",
    "for i in unique_prob:\n",
    "    data['y_thrshld'] = np.where(data['prob']>=i,1,0)\n",
    "    FP=len(data.loc[(data['y']==0) & (data['y_thrshld']==1)])\n",
    "    FN=len(data.loc[(data['y']==1) & (data['y_thrshld']==0)])\n",
    "    matric_value = (500*FN)+(100*FP)\n",
    "    if(matric_value<A):\n",
    "        A=matric_value\n",
    "        threshold_value = i\n",
    "    del data['y_thrshld']\n",
    "\n",
    "print(\"Matric value: \",A)\n",
    "print(\"Threshold value: \",threshold_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
    "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data= pd.read_csv(\"5_d.csv\")\n",
    "data\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error 177.16569974554707\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = data.y.values\n",
    "pred = data.pred.values\n",
    "MSE = np.square(np.subtract(y,pred)).mean()\n",
    "print(\"mean square error\",MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.16569974554707"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing with sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "y = data.y.values\n",
    "pred = data.pred.values\n",
    "p = mean_squared_error(y,pred)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.9563580010782354\n"
     ]
    }
   ],
   "source": [
    "def r2_val(y,pred):\n",
    "    a = sum((y-pred)**2)\n",
    "    b = (len(y)-1)*np.var(y)\n",
    "    r2_score = 1-(a/b)\n",
    "    return r2_score\n",
    "print(\"r2_score\",r2_val(y,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9563582786990937"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing with sklearn\n",
    "from sklearn.metrics import r2_score\n",
    "y = data.y.values\n",
    "pred = data.pred.values\n",
    "r2_score(y,pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.912029940096867"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MAPE(y,pred):\n",
    "    y,pred = np.array(y),np.array(pred)\n",
    "    l = np.mean(y)\n",
    "    return np.mean(np.abs((y-pred)/l))*100\n",
    "k = MAPE(y,pred)\n",
    "k"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
